{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eecb2f9",
   "metadata": {},
   "source": [
    "# 1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16d931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo # for importing datasets\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import wilcoxon\n",
    "import pymannkendall as mk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8505944",
   "metadata": {},
   "source": [
    "# 2 Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48fb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to fetch datasets from UCI machine learning repotory and make it into dataframe\n",
    "\n",
    "def fetch_datasets(dataset_id):\n",
    "    dataset = fetch_ucirepo(id = dataset_id)\n",
    "    \n",
    "    # data (as pandas dataframes) \n",
    "    X = dataset.data.features # pandas dataframe X\n",
    "    y = dataset.data.targets # pandas dataframe Y\n",
    "    \n",
    "    # join X and y into a whole dataframe\n",
    "    df = pd.concat([X,y], axis = 1)\n",
    "    df.to_excel(f'dataset.xlsx', index=False) # export to excel file\n",
    "#     df.shape # number of observations and number of variables\n",
    "    globals()[f\"ds{dataset_id}\"] = df\n",
    "    \n",
    "    return globals()[f\"ds{dataset_id}\"] # return a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf931f7",
   "metadata": {},
   "source": [
    "### 2.1 Import datasets - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf66251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States   <=50K  \n",
       "1      United-States   <=50K  \n",
       "2      United-States   <=50K  \n",
       "3      United-States   <=50K  \n",
       "4               Cuba   <=50K  \n",
       "...              ...     ...  \n",
       "48837  United-States  <=50K.  \n",
       "48838  United-States  <=50K.  \n",
       "48839  United-States  <=50K.  \n",
       "48840  United-States  <=50K.  \n",
       "48841  United-States   >50K.  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch datasets for size of datasets\n",
    "\n",
    "fetch_datasets(2) # id = 2 adult income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfff05-cf89-4b3c-bf97-13b128402b2d",
   "metadata": {},
   "source": [
    "### 2.2 Import datasets - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89fe7aa-7bf0-402a-9f00-c252e4861404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States   <=50K  \n",
       "1      United-States   <=50K  \n",
       "2      United-States   <=50K  \n",
       "3      United-States   <=50K  \n",
       "4               Cuba   <=50K  \n",
       "...              ...     ...  \n",
       "48837  United-States  <=50K.  \n",
       "48838  United-States  <=50K.  \n",
       "48839  United-States  <=50K.  \n",
       "48840  United-States  <=50K.  \n",
       "48841  United-States   >50K.  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch datasets for class balance datasets\n",
    "\n",
    "fetch_datasets(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615a2d8",
   "metadata": {},
   "source": [
    "### 2.3 Import datasets - C. Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459265f2-192b-4758-85f5-b73636a067e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch datasets for number of features datasets\n",
    "\n",
    "for ds_id in [75, 367,722]:\n",
    "    fetch_datasets(ds_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d28a21-135e-4f71-8e06-e93e3b74c115",
   "metadata": {},
   "source": [
    "### 2.4 Import datasets - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f5601f-1d34-404c-a870-ce84161a74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch datasets for binary or non-binary response variable\n",
    "\n",
    "binaryId = [159, 222, 367, 722, 891, 350] # remove 967, use 891\n",
    "ordinalId = [54, 146, 148, 78, 31, 107] # remove 1, use 31\n",
    "categoricalId = [697, 602, 26, 352, 23, 59] # remove 76, use 59\n",
    "\n",
    "binary_ds = []\n",
    "ordinal_ds = []\n",
    "categorical_ds = []\n",
    "\n",
    "for i in binaryId:\n",
    "    binary_ds.append(fetch_datasets(i))\n",
    "\n",
    "for j in ordinalId:\n",
    "    ordinal_ds.append(fetch_datasets(j))\n",
    "\n",
    "for z in categoricalId:\n",
    "    categorical_ds.append(fetch_datasets(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "763b7f8f-9c38-4fcf-a4ac-2f6455520ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dropout' 'Graduate' 'Enrolled']\n",
      "['SEKER' 'BARBUNYA' 'BOMBAY' 'CALI' 'HOROZ' 'SIRA' 'DERMASON']\n",
      "['win' 'draw' 'loss']\n",
      "['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
      " 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
      " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
      " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
      " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
      " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
      " 'European Community' 'Malta' 'RSA']\n",
      "['draw' 'zero' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'ten' 'eleven' 'twelve' 'thirteen' 'fourteen' 'fifteen' 'sixteen']\n",
      "['T' 'I' 'D' 'N' 'G' 'S' 'B' 'A' 'J' 'M' 'X' 'O' 'R' 'F' 'C' 'H' 'W' 'L'\n",
      " 'P' 'E' 'V' 'Y' 'Q' 'U' 'K' 'Z']\n"
     ]
    }
   ],
   "source": [
    "# observe characteristics of datasets\n",
    "for ds in categorical_ds:\n",
    "    print(ds.iloc[:,-1].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1351423",
   "metadata": {},
   "source": [
    "# 3 Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e9202-b68b-465d-ae68-95cc03715311",
   "metadata": {},
   "source": [
    "### 3.0 Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34c3ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to make data preprocessing\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    # # check for missing values\n",
    "    # print(df.isnull().sum())\n",
    "    \n",
    "    # remove rows of missing values\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "    # label-encoding\n",
    "    is_categorical = any(df.dtypes == 'object')\n",
    "    \n",
    "    if is_categorical:  # if dataframe has catogorical data\n",
    "        categorical_features = df.select_dtypes(include = ['object']).columns # extract categorical features\n",
    "\n",
    "        label_encoder = LabelEncoder() # label encoding\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c450784a-2f6d-4e12-932e-0ad86bc2714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for balance of a dataset\n",
    "\n",
    "def check_balance(ds):\n",
    "    y = ds.iloc[:,-1]\n",
    "    result = sorted(Counter(y).items())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4909450b-f494-461f-ba2b-48a65feb92d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a function to resample based on the given weight (use for module2 checking balanced or imbalanced)\n",
    "\n",
    "def resample_dataset(ds, whole_counts, proportion):\n",
    "    \n",
    "    category = ds.iloc[:,-1].unique() # extract the categories in original dataset\n",
    "    \n",
    "    sub_datasets = {} # create a dictionary to store all sub datasets based on the category\n",
    "    \n",
    "    # extract sub datasets based on category\n",
    "    for i, cat in enumerate(category):\n",
    "        sub_datasets[f\"sub_datasets{i+1}\"] = ds[ds.iloc[:,-1] == cat]\n",
    "    \n",
    "    for name, dataset in sub_datasets.items():\n",
    "        print(f\"The number of rows before resampling in {name} is {len(dataset)}.\")\n",
    "    \n",
    "    # resample each sub dataset\n",
    "    size1 = int(whole_counts * proportion) # number of rows from category 1 based on the given weight\n",
    "    size2 = whole_counts - size1 # number of rows given to cateogry 2\n",
    "    \n",
    "    resample1 = sub_datasets['sub_datasets1'].sample(n = size1, replace = True)\n",
    "    resample2 = sub_datasets['sub_datasets2'].sample(n = size2, replace = True)\n",
    "    print(f\"Rows after resampling are {len(resample1)} and {len(resample2)} respectively.\")\n",
    "\n",
    "    # combine resample1 and resample2 into a new dataframe\n",
    "    resample_ds = pd.concat([resample1, resample2])\n",
    "\n",
    "    # shuffle the combined dataset\n",
    "    resample_shuffle_ds = resample_ds.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return resample_shuffle_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1114d081-a360-4380-86e6-e914f145985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to process feature selection\n",
    "\n",
    "def feature_selection(ds, n):\n",
    "    X = ds.iloc[:, :-1]\n",
    "    y = ds.iloc[:, -1]\n",
    "    selector = SelectKBest(mutual_info_classif, k = n)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    df_selection = pd.DataFrame(X_new, columns = selected_features)\n",
    "    df_selection['target'] = y  \n",
    "    \n",
    "    return df_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6912c2ff-4b97-45df-860f-00df487ef656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to resample and return a balanced dataframe\n",
    "\n",
    "def resample_to_balance(ds):\n",
    "    X = ds.iloc[:, :-1]\n",
    "    y = ds.iloc[:, -1]\n",
    "    X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
    "    ds_resampled = pd.concat([X_resampled, y_resampled], axis = 1)\n",
    "    \n",
    "    return ds_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3a953",
   "metadata": {},
   "source": [
    "### 3.1 Data preprocessing - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e754af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K', '<=50K.', '>50K.'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for response value and remove noise\n",
    "\n",
    "ds2['income'].unique() # contains noise in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "900f034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2['income'] = ds2['income'].replace({'<=50K.':'<=50K', '>50K.':'>50K'})\n",
    "\n",
    "ds2['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "453a0b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>245211</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>215419</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>374983</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>83891</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>182148</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47621 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       39          7   77516          9             13               4   \n",
       "1       50          6   83311          9             13               2   \n",
       "2       38          4  215646         11              9               0   \n",
       "3       53          4  234721          1              7               2   \n",
       "4       28          4  338409          9             13               2   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "48836   33          4  245211          9             13               4   \n",
       "48837   39          4  215419          9             13               0   \n",
       "48839   38          4  374983          9             13               2   \n",
       "48840   44          4   83891          9             13               0   \n",
       "48841   35          5  182148          9             13               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               1             1     4    1          2174             0   \n",
       "1               4             0     4    1             0             0   \n",
       "2               6             1     4    1             0             0   \n",
       "3               6             0     2    1             0             0   \n",
       "4              10             5     2    0             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "48836          10             3     4    1             0             0   \n",
       "48837          10             1     4    0             0             0   \n",
       "48839          10             0     4    1             0             0   \n",
       "48840           1             3     1    1          5455             0   \n",
       "48841           4             0     4    1             0             0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0                  40              39       0  \n",
       "1                  13              39       0  \n",
       "2                  40              39       0  \n",
       "3                  40              39       0  \n",
       "4                  40               5       0  \n",
       "...               ...             ...     ...  \n",
       "48836              40              39       0  \n",
       "48837              36              39       0  \n",
       "48839              50              39       0  \n",
       "48840              40              39       0  \n",
       "48841              60              39       1  \n",
       "\n",
       "[47621 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessing(ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c7e6af5-5ec0-4963-81eb-ba81eae9575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different size of datasets\n",
    "\n",
    "large_datasets = [47621,45000,40000,38000,35000,30000,25000,20000,15000,10000]\n",
    "small_datasets = [50,100,200,300,400,500,600,700,800,900]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9b74d-3122-48f2-babc-ae4cf8f21405",
   "metadata": {},
   "source": [
    "### 3.2 Data preprocessing - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74290704-8750-4544-ab52-4c447aa677e6",
   "metadata": {},
   "source": [
    "#### 3.2.1 Check for balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5882be2d-89c7-45c3-b875-d205bb7ec972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47621, 15)\n",
      "income\n",
      "0    36080\n",
      "1    11541\n",
      "Name: count, dtype: int64\n",
      "income\n",
      "0    0.757649\n",
      "1    0.242351\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check for the balance of datasets\n",
    "\n",
    "print(ds2.shape)\n",
    "\n",
    "# check for the counts\n",
    "category_counts = ds2['income'].value_counts()\n",
    "print(category_counts)\n",
    "category_proportion = ds2['income'].value_counts(normalize = True)\n",
    "print(category_proportion) # before resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a475ba0-b955-4c25-8ea0-5e62b14f3f61",
   "metadata": {},
   "source": [
    "#### 3.2.2 Resample to datasets with different level of balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe725679-968c-43ba-a477-9c65461e2607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 46668 and 953 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 45239 and 2382 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 42858 and 4763 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 40477 and 7144 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 38096 and 9525 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 35715 and 11906 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 33334 and 14287 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 30953 and 16668 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 28572 and 19049 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 21905 and 25716 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 22381 and 25240 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 22858 and 24763 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 23334 and 24287 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 23810 and 23811 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 24286 and 23335 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 24762 and 22859 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 25239 and 22382 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 25715 and 21906 respectively.\n",
      "The number of rows before resampling in sub_datasets1 is 36080.\n",
      "The number of rows before resampling in sub_datasets2 is 11541.\n",
      "Rows after resampling are 26191 and 21430 respectively.\n"
     ]
    }
   ],
   "source": [
    "# create different weight of imbalanced datasets and balanced datasets\n",
    "\n",
    "imbalanced_datasets = [ds2] # create a new list to store all the imbalanced datasets, including the original dataset which is imbalanced too\n",
    "imbalanced_proportions = [0.98, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6] # given imbalanced rate\n",
    "balanced_datasets = []\n",
    "balanced_proportions = [0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55]\n",
    "\n",
    "# create imbalanced datasets based on the imbalanced weight\n",
    "for i in imbalanced_proportions:\n",
    "    imbalanced_datasets.append(resample_dataset(ds2, whole_counts, i))\n",
    "\n",
    "# create balanced datasets based on the balanced weight\\\n",
    "for j in balanced_proportions:\n",
    "    balanced_datasets.append(resample_dataset(ds2, whole_counts, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fcb8a3",
   "metadata": {},
   "source": [
    "### 3.3 Data preprocessing - C. Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa17214-fbbe-469f-8fa3-33b7aa72084b",
   "metadata": {},
   "source": [
    "#### 3.3.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f116bc1c-55fe-4ccf-944b-86c1107f9b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_preprocessed = []\n",
    "for ds in [ds75, ds367, ds722]:\n",
    "    features_preprocessed.append(data_preprocessing(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d44ae74-2e51-4c9c-96e9-b7f7fedcb2a4",
   "metadata": {},
   "source": [
    "#### 3.3.2 Create new datasets with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f84e4036-3379-478b-9f40-6ff1e6e7be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feauture selection with ds75\n",
    "\n",
    "features_ds75 = []\n",
    "for n in [135, 110, 95, 75, 60, 45, 30, 15, 5]:\n",
    "    a = feature_selection(features_preprocessed[0], n)\n",
    "    features_ds75.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d4a77bf-f11b-4b87-9e0e-f89d6ed9f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with ds367\n",
    "\n",
    "features_ds367 = []\n",
    "for n in [100, 88, 76, 64, 52, 40, 28, 16, 4]:\n",
    "    a = feature_selection(features_preprocessed[1], n)\n",
    "    features_ds367.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ee910f6-b168-4fa0-9ddc-5341a309d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with ds722\n",
    "\n",
    "features_ds722 = []\n",
    "for n in [78, 69, 60, 51, 42, 33, 24, 15, 6]:\n",
    "    a = feature_selection(features_preprocessed[2], n)\n",
    "    features_ds722.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f4ba3-5f56-4c0b-abfc-17095e483249",
   "metadata": {},
   "source": [
    "#### 3.3.2 Check for balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2f9e8cc3-bc41-4442-9503-2c4f45666bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 5581), (1.0, 1017)]\n",
      "[(-1, 48660), (1, 54284)]\n",
      "[(0, 14632), (1, 14700)]\n",
      "[(0, 100945), (1, 134850)]\n"
     ]
    }
   ],
   "source": [
    "# check balance of the datasets\n",
    "\n",
    "print(check_balance(features_ds75[0]))\n",
    "print(check_balance(features_ds367[0]))\n",
    "print(check_balance(features_ds722[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fa1fe-7da0-4989-901e-223a27e03d4c",
   "metadata": {},
   "source": [
    "### 3.4 Data preprocessing - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e0aca-a1d4-406c-b2df-3e09519f1a65",
   "metadata": {},
   "source": [
    "#### 3.4.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b53afb45-012d-4409-a79e-4dc9f8797d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binary and ordinal\n",
    "binary_ds_preprocessed = []\n",
    "ordinal_ds_preprocessed = []\n",
    "categorical_ds_preprocessed = []\n",
    "\n",
    "for i in binary_ds:\n",
    "    binary_ds_preprocessed.append(data_preprocessing(i))\n",
    "for j in ordinal_ds:\n",
    "    ordinal_ds_preprocessed.append(data_preprocessing(j))\n",
    "for z in categorical_ds:\n",
    "    categorical_ds_preprocessed.append(data_preprocessing(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54657abd-6aaf-4011-bf76-7c320a38468b",
   "metadata": {},
   "source": [
    "#### 3.4.2 Check for balance and dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "379ee789-c6a0-4c4e-b373-daf8dd82bbaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[(0, 12332), (1, 6688)]\n",
      "(19020, 11)\n",
      "1\n",
      "[(0, 6056), (1, 1786)]\n",
      "(7842, 17)\n",
      "2\n",
      "[(-1, 48660), (1, 54284)]\n",
      "(102944, 116)\n",
      "3\n",
      "[(0, 14632), (1, 14700)]\n",
      "(29332, 87)\n",
      "4\n",
      "[(0, 218334), (1, 35346)]\n",
      "(253680, 22)\n",
      "5\n",
      "[(0, 23364), (1, 6636)]\n",
      "(30000, 24)\n"
     ]
    }
   ],
   "source": [
    "# binary check\n",
    "index = 0\n",
    "for i in binary_ds_preprocessed:\n",
    "    print(index)\n",
    "    print(check_balance(i)) # check for balance\n",
    "    print(i.shape) # check for dimension\n",
    "    index += 1\n",
    "\n",
    "# need resample: [0, 1, 4 5]\n",
    "# features: 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "68fd7ffe-8d48-4260-80a1-d97bc3b8495e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[(1.0, 300), (2.0, 300), (3.0, 300), (4.0, 300), (5.0, 300), (6.0, 298), (7.0, 300), (8.0, 300), (9.0, 300), (10.0, 300), (11.0, 300), (12.0, 300), (13.0, 299), (14.0, 300), (15.0, 300), (16.0, 300), (17.0, 300), (18.0, 300), (19.0, 300), (20.0, 300), (21.0, 300), (22.0, 300), (23.0, 300), (24.0, 300), (25.0, 300), (26.0, 300)]\n",
      "(7797, 618)\n",
      "\n",
      "\n",
      "1\n",
      "[(1, 1533), (2, 703), (3, 1358), (4, 626), (5, 707), (7, 1508)]\n",
      "(6435, 37)\n",
      "\n",
      "\n",
      "2\n",
      "[(1, 45586), (2, 50), (3, 171), (4, 8903), (5, 3267), (6, 10), (7, 13)]\n",
      "(58000, 8)\n",
      "\n",
      "\n",
      "3\n",
      "[(1, 4913), (2, 329), (3, 28), (4, 88), (5, 115)]\n",
      "(5473, 11)\n",
      "\n",
      "\n",
      "4\n",
      "[(1, 211840), (2, 283301), (3, 35754), (4, 2747), (5, 9493), (6, 17367), (7, 20510)]\n",
      "(581012, 55)\n",
      "\n",
      "\n",
      "5\n",
      "[(0, 1657), (1, 1647), (2, 1696)]\n",
      "(5000, 22)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ordinal check\n",
    "index = 0\n",
    "for i in ordinal_ds_preprocessed:\n",
    "    print(index)\n",
    "    print(check_balance(i))\n",
    "    print(i.shape)\n",
    "    print(\"\\n\")\n",
    "    index += 1\n",
    "    \n",
    "# need resample: [1, 2, 3, 4]\n",
    "# features: 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e7a17e4-d67e-4cf2-b24f-91a3173df79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[(0, 1421), (1, 794), (2, 2209)]\n",
      "(4424, 37)\n",
      "\n",
      "\n",
      "1\n",
      "[(0, 1322), (1, 522), (2, 1630), (3, 3546), (4, 1928), (5, 2027), (6, 2636)]\n",
      "(13611, 17)\n",
      "\n",
      "\n",
      "2\n",
      "[(0, 6449), (1, 16635), (2, 44473)]\n",
      "(67557, 43)\n",
      "\n",
      "\n",
      "3\n",
      "[(0, 1259), (1, 401), (2, 17), (3, 2069), (4, 32), (5, 151), (6, 758), (7, 622), (8, 30), (9, 389), (10, 7485), (11, 61), (12, 695), (13, 8491), (14, 9495), (15, 146), (16, 182), (17, 250), (18, 803), (19, 358), (20, 45), (21, 35), (22, 127), (23, 2371), (24, 1086), (25, 341), (26, 1480), (27, 58), (28, 10), (29, 229), (30, 2533), (31, 462), (32, 1877), (33, 291), (34, 68), (35, 361878), (36, 244)]\n",
      "(406829, 6)\n",
      "\n",
      "\n",
      "4\n",
      "[(0, 2796), (1, 1433), (2, 2854), (3, 2166), (4, 471), (5, 198), (6, 4553), (7, 1712), (8, 78), (9, 683), (10, 592), (11, 390), (12, 1985), (13, 4194), (14, 81), (15, 3597), (16, 246), (17, 27)]\n",
      "(28056, 7)\n",
      "\n",
      "\n",
      "5\n",
      "[(0, 789), (1, 766), (2, 736), (3, 805), (4, 768), (5, 775), (6, 773), (7, 734), (8, 755), (9, 747), (10, 739), (11, 761), (12, 792), (13, 783), (14, 753), (15, 803), (16, 783), (17, 758), (18, 748), (19, 796), (20, 813), (21, 764), (22, 752), (23, 787), (24, 786), (25, 734)]\n",
      "(20000, 17)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# categorical check\n",
    "index = 0\n",
    "for i in categorical_ds_preprocessed:\n",
    "    print(index)\n",
    "    print(check_balance(i))\n",
    "    print(i.shape)\n",
    "    print(\"\\n\")\n",
    "    index += 1\n",
    "\n",
    "# need resample: [0, 1, 2, 3, 4]\n",
    "# features: 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64337070-9bfd-444d-9462-6a6f49ebf62c",
   "metadata": {},
   "source": [
    "#### 3.4.3 Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560afa4b-31fc-47e1-856c-3fe65eefff3f",
   "metadata": {},
   "source": [
    "#### 3.4.3.1 for binary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e6fc9fb-7120-4f76-b228-c96b63c49678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of binary datasets\n",
      "[(0, 12332), (1, 6688)]\n",
      "[(0, 6056), (1, 1786)]\n",
      "[(-1, 48660), (1, 54284)]\n",
      "[(0, 14632), (1, 14700)]\n",
      "[(0, 218334), (1, 35346)]\n",
      "[(0, 23364), (1, 6636)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of binary datasets\")\n",
    "for i in binary_ds_preprocessed:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c468f818-497f-474c-b8a8-08356d071309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary need resample: [0, 1, 4, 5]\n",
    "binary_ds_resample = []\n",
    "\n",
    "for i in [0, 1, 4, 5]:\n",
    "    a = binary_ds_preprocessed[i]\n",
    "    result = resample_to_balance(a)\n",
    "    binary_ds_resample.append(result)\n",
    "\n",
    "for j in [2, 3]:\n",
    "    b = binary_ds_preprocessed[j]\n",
    "    binary_ds_resample.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aec1d54f-b283-43a8-8d4d-4f67db5cd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of binary datasets after resampling:\n",
      "[(0, 12332), (1, 11953)]\n",
      "[(0, 6056), (1, 5865)]\n",
      "[(0, 218334), (1, 214093)]\n",
      "[(0, 23364), (1, 23941)]\n",
      "[(-1, 48660), (1, 54284)]\n",
      "[(0, 14632), (1, 14700)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of binary datasets after resampling:\")\n",
    "for i in binary_ds_resample:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35585c-1ca7-4a30-bba1-d01eb50f0d3b",
   "metadata": {},
   "source": [
    "#### 3.4.3.2 for ordinal datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "86b61306-bf35-4c95-99db-3cafbfffc7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of ordinal datasets:\n",
      "[(1.0, 300), (2.0, 300), (3.0, 300), (4.0, 300), (5.0, 300), (6.0, 298), (7.0, 300), (8.0, 300), (9.0, 300), (10.0, 300), (11.0, 300), (12.0, 300), (13.0, 299), (14.0, 300), (15.0, 300), (16.0, 300), (17.0, 300), (18.0, 300), (19.0, 300), (20.0, 300), (21.0, 300), (22.0, 300), (23.0, 300), (24.0, 300), (25.0, 300), (26.0, 300)]\n",
      "[(1, 1533), (2, 703), (3, 1358), (4, 626), (5, 707), (7, 1508)]\n",
      "[(1, 45586), (2, 50), (3, 171), (4, 8903), (5, 3267), (6, 10), (7, 13)]\n",
      "[(1, 4913), (2, 329), (3, 28), (4, 88), (5, 115)]\n",
      "[(1, 211840), (2, 283301), (3, 35754), (4, 2747), (5, 9493), (6, 17367), (7, 20510)]\n",
      "[(0, 1657), (1, 1647), (2, 1696)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of ordinal datasets:\")\n",
    "for i in ordinal_ds_preprocessed:\n",
    "    print(check_balance(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09f868f9-8320-4623-8112-e84d7010c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal need resample: [2, 3, 4]\n",
    "\n",
    "ordinal_ds_resample = []\n",
    "\n",
    "for i in [2, 3, 4]:\n",
    "    a = ordinal_ds_preprocessed[i]\n",
    "    result = resample_to_balance(a)\n",
    "    ordinal_ds_resample.append(result)\n",
    "\n",
    "for j in [0, 1, 5]:\n",
    "    b = ordinal_ds_preprocessed[j]\n",
    "    ordinal_ds_resample.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0d8eb3cd-d5c2-476c-b108-2a2a8bdc71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of ordinal datasets after resampling:\n",
      "[(1, 45586), (2, 45591), (3, 45567), (4, 45578), (5, 45579), (6, 45586), (7, 45587)]\n",
      "[(1, 4913), (2, 4905), (3, 4913), (4, 4914), (5, 4919)]\n",
      "[(1, 277115), (2, 283301), (3, 282296), (4, 283284), (5, 283455), (6, 282678), (7, 282914)]\n",
      "[(1.0, 300), (2.0, 300), (3.0, 300), (4.0, 300), (5.0, 300), (6.0, 298), (7.0, 300), (8.0, 300), (9.0, 300), (10.0, 300), (11.0, 300), (12.0, 300), (13.0, 299), (14.0, 300), (15.0, 300), (16.0, 300), (17.0, 300), (18.0, 300), (19.0, 300), (20.0, 300), (21.0, 300), (22.0, 300), (23.0, 300), (24.0, 300), (25.0, 300), (26.0, 300)]\n",
      "[(1, 1533), (2, 703), (3, 1358), (4, 626), (5, 707), (7, 1508)]\n",
      "[(0, 1657), (1, 1647), (2, 1696)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of ordinal datasets after resampling:\")\n",
    "for i in ordinal_ds_resample:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb6396-dc86-400f-936b-8a2a9fcef927",
   "metadata": {},
   "source": [
    "#### 3.4.3.3 for categorical datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c857f70-1e7a-4192-8c04-707052c2f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of categorical datasets:\n",
      "[(0, 1421), (1, 794), (2, 2209)]\n",
      "[(0, 1322), (1, 522), (2, 1630), (3, 3546), (4, 1928), (5, 2027), (6, 2636)]\n",
      "[(0, 6449), (1, 16635), (2, 44473)]\n",
      "[(0, 1259), (1, 401), (2, 17), (3, 2069), (4, 32), (5, 151), (6, 758), (7, 622), (8, 30), (9, 389), (10, 7485), (11, 61), (12, 695), (13, 8491), (14, 9495), (15, 146), (16, 182), (17, 250), (18, 803), (19, 358), (20, 45), (21, 35), (22, 127), (23, 2371), (24, 1086), (25, 341), (26, 1480), (27, 58), (28, 10), (29, 229), (30, 2533), (31, 462), (32, 1877), (33, 291), (34, 68), (35, 361878), (36, 244)]\n",
      "[(0, 2796), (1, 1433), (2, 2854), (3, 2166), (4, 471), (5, 198), (6, 4553), (7, 1712), (8, 78), (9, 683), (10, 592), (11, 390), (12, 1985), (13, 4194), (14, 81), (15, 3597), (16, 246), (17, 27)]\n",
      "[(0, 789), (1, 766), (2, 736), (3, 805), (4, 768), (5, 775), (6, 773), (7, 734), (8, 755), (9, 747), (10, 739), (11, 761), (12, 792), (13, 783), (14, 753), (15, 803), (16, 783), (17, 758), (18, 748), (19, 796), (20, 813), (21, 764), (22, 752), (23, 787), (24, 786), (25, 734)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of categorical datasets:\")\n",
    "for i in categorical_ds_preprocessed:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b25dab89-d33e-457c-958f-433aeb7cc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical need resample: [0, 1, 2, 3]\n",
    "categorical_ds_resample = []\n",
    "\n",
    "for i in [0, 1, 2, 3]:\n",
    "    a = categorical_ds_preprocessed[i]\n",
    "    result = resample_to_balance(a)\n",
    "    categorical_ds_resample.append(result)\n",
    "\n",
    "for j in [4, 5]:\n",
    "    b = categorical_ds_preprocessed[j]\n",
    "    categorical_ds_resample.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "256d8667-7de7-4f86-a613-c3a21f32e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance of categorical datasets after resampling:\n",
      "[(0, 2187), (1, 2027), (2, 2209)]\n",
      "[(0, 3466), (1, 3546), (2, 3679), (3, 3546), (4, 3310), (5, 3320), (6, 3320)]\n",
      "[(0, 43553), (1, 46031), (2, 44473)]\n",
      "[(0, 361879), (1, 361894), (2, 361878), (3, 361873), (4, 361875), (5, 361877), (6, 361835), (7, 361867), (8, 361878), (9, 361886), (10, 362711), (11, 361877), (12, 361909), (13, 361483), (14, 362255), (15, 361852), (16, 361872), (17, 361880), (18, 361908), (19, 361830), (20, 361867), (21, 361877), (22, 361867), (23, 361818), (24, 362036), (25, 361918), (26, 361805), (27, 361881), (28, 361879), (29, 361849), (30, 362007), (31, 361882), (32, 361760), (33, 361860), (34, 361881), (35, 361878), (36, 361889)]\n",
      "[(0, 2796), (1, 1433), (2, 2854), (3, 2166), (4, 471), (5, 198), (6, 4553), (7, 1712), (8, 78), (9, 683), (10, 592), (11, 390), (12, 1985), (13, 4194), (14, 81), (15, 3597), (16, 246), (17, 27)]\n",
      "[(0, 789), (1, 766), (2, 736), (3, 805), (4, 768), (5, 775), (6, 773), (7, 734), (8, 755), (9, 747), (10, 739), (11, 761), (12, 792), (13, 783), (14, 753), (15, 803), (16, 783), (17, 758), (18, 748), (19, 796), (20, 813), (21, 764), (22, 752), (23, 787), (24, 786), (25, 734)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Balance of categorical datasets after resampling:\")\n",
    "for i in categorical_ds_resample:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a8210-015f-4320-b33e-7b1356348c73",
   "metadata": {},
   "source": [
    "#### 3.4.4 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7ec4b6f3-0296-422d-960d-b2545ffdab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24285, 11)\n",
      "(11921, 17)\n",
      "(432427, 22)\n",
      "(47305, 24)\n",
      "(102944, 116)\n",
      "(29332, 87)\n"
     ]
    }
   ],
   "source": [
    "# check for dimension\n",
    "for i in binary_ds_resample:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9c8ed4f6-ec8d-4eea-9f40-e8c3e7b59c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary datasets\n",
    "# need feature selection: [3, 4, 5]\n",
    "# features: 23\n",
    "\n",
    "binary_features = 23\n",
    "binary_ds_feature_selection = []\n",
    "\n",
    "for i in [3, 4, 5]:\n",
    "    ds = binary_ds_resample[i]\n",
    "    a = feature_selection(ds, binary_features) # feature selection\n",
    "    binary_ds_feature_selection.append(a)\n",
    "\n",
    "for j in [0, 1, 2]:\n",
    "    b = binary_ds_resample[j]\n",
    "    binary_ds_feature_selection.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "142e6578-38fd-4054-a338-d13c9b5830c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319074, 8)\n",
      "(24564, 11)\n",
      "(1975043, 55)\n",
      "(7797, 618)\n",
      "(6435, 37)\n",
      "(5000, 22)\n"
     ]
    }
   ],
   "source": [
    "# check for dimension\n",
    "for i in ordinal_ds_resample:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1b6cd9ed-604a-4d7b-b7da-42bcb0072779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7797, 18)\n",
      "(6435, 18)\n",
      "(5000, 18)\n",
      "(319074, 8)\n",
      "(24564, 11)\n",
      "(1975043, 55)\n"
     ]
    }
   ],
   "source": [
    "# ordinal datasets\n",
    "# need feature selection: [3, 4, 5]\n",
    "# features: 17\n",
    "\n",
    "ordinal_features = 17\n",
    "ordinal_ds_feature_selection = []\n",
    "\n",
    "for i in [3, 4, 5]:\n",
    "    ds = ordinal_ds_resample[i]\n",
    "    a = feature_selection(ds, ordinal_features) # feature selection\n",
    "    ordinal_ds_feature_selection.append(a)\n",
    "\n",
    "for j in [0, 1, 2]:\n",
    "    b = ordinal_ds_resample[j]\n",
    "    ordinal_ds_feature_selection.append(b)\n",
    "\n",
    "# check for dimension after feature selection\n",
    "for z in ordinal_ds_feature_selection:\n",
    "    print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "40de9921-27de-4bfa-b9b2-ea4efc120326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6423, 37)\n",
      "(24187, 17)\n",
      "(134057, 43)\n",
      "(13390273, 6)\n",
      "(28056, 7)\n",
      "(20000, 17)\n"
     ]
    }
   ],
   "source": [
    "# check for dimension\n",
    "for i in categorical_ds_resample:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f7d9b736-c510-4991-b4cc-643038fc1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6423, 18)\n",
      "(134057, 18)\n",
      "(24187, 17)\n",
      "(13390273, 6)\n",
      "(28056, 7)\n",
      "(20000, 17)\n"
     ]
    }
   ],
   "source": [
    "# categorical datasets\n",
    "# need feature selection: [0, 2]\n",
    "# features: 17\n",
    "\n",
    "categorical_features = 17\n",
    "categorical_ds_feature_selection = []\n",
    "\n",
    "for i in [0, 2]:\n",
    "    ds = categorical_ds_resample[i]\n",
    "    a = feature_selection(ds, categorical_features) # feature selection\n",
    "    categorical_ds_feature_selection.append(a)\n",
    "\n",
    "for j in [1, 3, 4, 5]:\n",
    "    b = categorical_ds_resample[j]\n",
    "    categorical_ds_feature_selection.append(b)\n",
    "\n",
    "# check for dimension after feature selection\n",
    "for z in categorical_ds_feature_selection:\n",
    "    print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a04be415-090e-4583-9bf2-5e2620408932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2187), (1, 2027), (2, 2209)]\n",
      "[(0, 43553), (1, 46031), (2, 44473)]\n",
      "[(0, 3466), (1, 3546), (2, 3679), (3, 3546), (4, 3310), (5, 3320), (6, 3320)]\n",
      "[(0, 361879), (1, 361894), (2, 361878), (3, 361873), (4, 361875), (5, 361877), (6, 361835), (7, 361867), (8, 361878), (9, 361886), (10, 362711), (11, 361877), (12, 361909), (13, 361483), (14, 362255), (15, 361852), (16, 361872), (17, 361880), (18, 361908), (19, 361830), (20, 361867), (21, 361877), (22, 361867), (23, 361818), (24, 362036), (25, 361918), (26, 361805), (27, 361881), (28, 361879), (29, 361849), (30, 362007), (31, 361882), (32, 361760), (33, 361860), (34, 361881), (35, 361878), (36, 361889)]\n",
      "[(0, 2796), (1, 1433), (2, 2854), (3, 2166), (4, 471), (5, 198), (6, 4553), (7, 1712), (8, 78), (9, 683), (10, 592), (11, 390), (12, 1985), (13, 4194), (14, 81), (15, 3597), (16, 246), (17, 27)]\n",
      "[(0, 789), (1, 766), (2, 736), (3, 805), (4, 768), (5, 775), (6, 773), (7, 734), (8, 755), (9, 747), (10, 739), (11, 761), (12, 792), (13, 783), (14, 753), (15, 803), (16, 783), (17, 758), (18, 748), (19, 796), (20, 813), (21, 764), (22, 752), (23, 787), (24, 786), (25, 734)]\n"
     ]
    }
   ],
   "source": [
    "# check balance\n",
    "for i in categorical_ds_feature_selection:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6d2aad7d-8302-4625-b83f-d4ca0aa0a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2187), (1, 2027), (2, 2209)]\n",
      "[(0, 43553), (1, 46031), (2, 44473)]\n",
      "[(0, 3466), (1, 3546), (2, 3679), (3, 3546), (4, 3310), (5, 3320), (6, 3320)]\n",
      "[(0, 361879), (1, 361894), (2, 361878), (3, 361873), (4, 361875), (5, 361877), (6, 361835), (7, 361867), (8, 361878), (9, 361886), (10, 362711), (11, 361877), (12, 361909), (13, 361483), (14, 362255), (15, 361852), (16, 361872), (17, 361880), (18, 361908), (19, 361830), (20, 361867), (21, 361877), (22, 361867), (23, 361818), (24, 362036), (25, 361918), (26, 361805), (27, 361881), (28, 361879), (29, 361849), (30, 362007), (31, 361882), (32, 361760), (33, 361860), (34, 361881), (35, 361878), (36, 361889)]\n",
      "[(0, 2796), (1, 1433), (2, 2854), (3, 2166), (4, 471), (5, 198), (6, 4553), (7, 1712), (9, 683), (10, 592), (11, 390), (12, 1985), (13, 4194), (15, 3597), (16, 246)]\n",
      "[(0, 789), (1, 766), (2, 736), (3, 805), (4, 768), (5, 775), (6, 773), (7, 734), (8, 755), (9, 747), (10, 739), (11, 761), (12, 792), (13, 783), (14, 753), (15, 803), (16, 783), (17, 758), (18, 748), (19, 796), (20, 813), (21, 764), (22, 752), (23, 787), (24, 786), (25, 734)]\n"
     ]
    }
   ],
   "source": [
    "# for categorical_ds_feature_selection[4], remove category[8, 14, 17]\n",
    "\n",
    "df = categorical_ds_feature_selection[4]\n",
    "response_name = df.columns[-1]\n",
    "specific_value = [8, 14, 17]\n",
    "df_filtered = df[~df[response_name].isin(specific_value)]\n",
    "\n",
    "categorical_ds_feature_selection[4] = df_filtered\n",
    "\n",
    "for i in categorical_ds_feature_selection:\n",
    "    print(check_balance(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95a59d-258f-42ee-ad5d-6850eae106ea",
   "metadata": {},
   "source": [
    "#### 3.4.5 Adjusting size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f9c6dcc0-a64b-460e-a55e-193a6c516a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6423\n",
      "134057\n",
      "24187\n",
      "13390273\n",
      "27870\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# check for size\n",
    "for i in categorical_ds_feature_selection:\n",
    "    print(i.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5e923459-d63e-498e-a27d-06ae372b54cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum size of all the datasets is 5000!\n"
     ]
    }
   ],
   "source": [
    "sizelist = []\n",
    "\n",
    "for datasets in [binary_ds_feature_selection, ordinal_ds_feature_selection, categorical_ds_feature_selection]:\n",
    "    for ds in datasets:\n",
    "        size = ds.shape[0]\n",
    "        sizelist.append(size)\n",
    "        \n",
    "minsize = min(sizelist)\n",
    "print(f\"The minimum size of all the datasets is {minsize}!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c0f47bb2-9523-4d37-a3f1-0baa1c36875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling in accordance to the same size\n",
    "binary_sample = []\n",
    "ordinal_sample = []\n",
    "categorical_sample = []\n",
    "\n",
    "for a in binary_ds_feature_selection:\n",
    "    a_sample = a.sample(n = minsize, random_state = 42)\n",
    "    binary_sample.append(a_sample)\n",
    "for b in ordinal_ds_feature_selection:\n",
    "    b_sample = b.sample(n = minsize, random_state = 42)\n",
    "    ordinal_sample.append(b_sample)\n",
    "for c in categorical_ds_feature_selection:\n",
    "    c_sample = c.sample(n = minsize, random_state = 42)\n",
    "    categorical_sample.append(c_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd15da4-1d05-4c1a-89a5-75db686bfc24",
   "metadata": {},
   "source": [
    "#### 3.4.6 One-hot encoding for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7565612f-bb8c-47a4-8240-b2f4637a8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "categorical_one_hot = []\n",
    "\n",
    "for ds in categorical_sample:\n",
    "    response_name = ds.columns[-1]\n",
    "    ds_one_hot = pd.get_dummies(ds, columns = [response_name], drop_first = True)\n",
    "    ds_one_hot_int = ds_one_hot.astype(int)\n",
    "    categorical_one_hot.append(ds_one_hot_int)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9f4a9390-c125-4d6e-8f90-ebac7eacf1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_datasets = binary_sample\n",
    "ordinal_datasets = ordinal_sample\n",
    "categorical_datasets = categorical_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd30df5",
   "metadata": {},
   "source": [
    "# 4 Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a12eed2c-a229-4e40-b62e-4f8dbfcf1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that store all models\n",
    "models = {\n",
    "    'Logistic Regression': make_pipeline(LogisticRegression(random_state=42)),\n",
    "    'Random Forest': make_pipeline(RandomForestClassifier(random_state=42)),\n",
    "    'KNN': make_pipeline(MinMaxScaler(), KNeighborsClassifier(n_neighbors = 5)), # need normalization\n",
    "    'SVM': make_pipeline(MinMaxScaler(), SVC(probability=True, random_state=42)) # need normalization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41ce49",
   "metadata": {},
   "source": [
    "# 5 AUC score matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6aadc-b7e8-4641-8a89-0071c3ca8f9b",
   "metadata": {},
   "source": [
    "### 5.0 Define functions for calculating AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5964008b-9a80-47af-a323-f5615686ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for calculating AUC score of singe classifier\n",
    "\n",
    "def AUC_single_binary(dataframe): # for binary response datasets\n",
    "    m = 4 # number of models\n",
    "    X = dataframe.iloc[:, :-1] # take first 14 columns as predictor variables\n",
    "    y = dataframe.iloc[:, -1] # take the last column as response variables\n",
    "    # split the dataset into training and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "    \n",
    "    auc_single = np.zeros(m)\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 42) # define k fold cross validation\n",
    "    # run all models\n",
    "    count = 0\n",
    "    for name, model in models.items():\n",
    "        auc_scores = cross_val_score(model, X_train, y_train, cv = kf, scoring = 'roc_auc') # introduce cross validation\n",
    "        auc_single[count] = auc_scores.mean()\n",
    "        count += 1\n",
    "        \n",
    "    return auc_single # auc score of all classifiers in one dataset (binary response)\n",
    "\n",
    "def AUC_single_multiclass(dataframe): # for multiclass response datasets\n",
    "    m = 4 # number of models\n",
    "    X = dataframe.iloc[:, :-1] # take first 14 columns as predictor variables\n",
    "    y = dataframe.iloc[:, -1] # take the last column as response variables\n",
    "    # split the dataset into training and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y) # stratified sampling\n",
    "    X_model = X_train\n",
    "    y_model = y_train\n",
    "\n",
    "    auc_single = np.zeros(m) # create an empty auc matrix for single model\n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True) # introduce stratified K fold\n",
    "    count = 0\n",
    "    for name, model in models.items():\n",
    "        roc_auc_scorer = make_scorer(roc_auc_score, needs_proba = True, multi_class = 'ovr')  # multiclass AUC score\n",
    "        auc_scores = cross_val_score(model, X_model, y_model, cv = skf, scoring = roc_auc_scorer)\n",
    "        auc_single[count] = auc_scores.mean()\n",
    "        # model.fit(X_train, y_train)\n",
    "        # y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        # auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        # auc_single[count] = auc # auc score for one model\n",
    "        count += 1\n",
    "        \n",
    "    return auc_single # auc score of all classifiers in one dataset (multiclass response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8e5f8e36-fbd2-4a77-b639-c2fe4aa25082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for generating the AUC matrix\n",
    "\n",
    "def AUC_Score_Matrix(type_datasets):\n",
    "    m = 4 # number of models\n",
    "    auc_all = np.zeros((len(type_datasets), m)) # create a new auc matrix that store all models\n",
    "\n",
    "    for i in range(len(type_datasets)): # for every dataset in the list\n",
    "    # module 1 : dataset size\n",
    "        if type_datasets is large_datasets or type_datasets is small_datasets:\n",
    "            # sample the dataframe\n",
    "            dataframe = ds2.sample(n = type_datasets[i], random_state = 42) # sample the dataset according to the predefined size\n",
    "            auc_all[i] = AUC_single_binary(dataframe)\n",
    "            \n",
    "    # module 2 & 3 : dataset balance & feature dimensionality\n",
    "        elif type_datasets is balanced_datasets or type_datasets is imbalanced_datasets or type_datasets is features_ds367 or type_datasets is features_ds722 or type_datasets is binary_datasets: \n",
    "            dataframe = type_datasets[i]\n",
    "            auc_all[i] = AUC_single_binary(dataframe)\n",
    "        \n",
    "        elif type_datasets is features_ds75: # because ds75 is imbalanced, it need resample\n",
    "            dataframe = type_datasets[i]\n",
    "            auc_all[i] = AUC_single_binary(dataframe)     \n",
    "            \n",
    "    # module 4: binary or non-binary datasets        \n",
    "        elif type_datasets is ordinal_datasets or type_datasets is categorical_datasets: # ordinal or categorical datasets\n",
    "            dataframe = type_datasets[i]\n",
    "            auc_all[i] = AUC_single_multiclass(dataframe)\n",
    "         \n",
    "    return auc_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac288cc5",
   "metadata": {},
   "source": [
    "### 5.1 AUC score matrix - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "feb8d840-2bea-4cb1-b01a-c7cea7dcb0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score matrix of all models for large datasets is shown below:\n",
      "\n",
      "[[0.69539226 0.90727513 0.84426688 0.89256684]\n",
      " [0.72397659 0.90581826 0.84539995 0.89302327]\n",
      " [0.68974023 0.9047379  0.8427893  0.89286139]\n",
      " [0.65431596 0.90486471 0.84415209 0.8930976 ]\n",
      " [0.72452882 0.90510334 0.84092227 0.89143033]\n",
      " [0.69938951 0.90285384 0.84008703 0.88953524]\n",
      " [0.69052365 0.90553258 0.84017649 0.89426709]\n",
      " [0.6958603  0.90267355 0.83609486 0.89122538]\n",
      " [0.68538123 0.89995713 0.83246108 0.88769292]\n",
      " [0.69268814 0.89707672 0.8287755  0.88467313]]\n",
      "\n",
      "\n",
      "The AUC score matrix of all models for small datasets is shown below:\n",
      "\n",
      "[[0.47333333 0.77333333 0.85666667 0.81333333]\n",
      " [0.65008936 0.84768939 0.81885101 0.88244949]\n",
      " [0.58648099 0.81791279 0.72824097 0.80607519]\n",
      " [0.56291808 0.8072782  0.72604592 0.78991497]\n",
      " [0.64128982 0.80940102 0.7172785  0.76121492]\n",
      " [0.68150623 0.83685872 0.74190029 0.81739368]\n",
      " [0.52023997 0.85267849 0.80691398 0.83827936]\n",
      " [0.60486937 0.84857353 0.77887418 0.82590504]\n",
      " [0.6432015  0.86140044 0.75897533 0.82131498]\n",
      " [0.71485078 0.85963112 0.73623246 0.82979098]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix for size of datasets\n",
    "\n",
    "auc_matrix_large = AUC_Score_Matrix(large_datasets)\n",
    "auc_matrix_small = AUC_Score_Matrix(small_datasets)\n",
    "\n",
    "print(\"The AUC score matrix of all models for large datasets is shown below:\\n\")\n",
    "print(auc_matrix_large)\n",
    "print(\"\\n\")\n",
    "print(\"The AUC score matrix of all models for small datasets is shown below:\\n\")\n",
    "print(auc_matrix_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48d9cb29-ae90-47a0-a015-0652d4ce81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_large = pd.DataFrame(auc_matrix_large, columns = classifiers)\n",
    "df_auc_small = pd.DataFrame(auc_matrix_small, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_large.to_csv('pythonAUC_large_datasets.csv', index = False)\n",
    "df_auc_small.to_csv('pythonAUC_small_datasets.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcff918-6b88-4155-8dbb-ac222da842d1",
   "metadata": {},
   "source": [
    "### 5.2 AUC score matrix - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f835484d-4b5a-454d-b54b-81871be73250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score matrix of all models for imbalanced datasets is shown below:\n",
      "\n",
      "[[0.6211682  0.90570501 0.84363928 0.89490902]\n",
      " [0.55416446 0.88916787 0.68779502 0.84864036]\n",
      " [0.58399394 0.92580355 0.76864926 0.87488341]\n",
      " [0.6263118  0.94215407 0.82554887 0.88786047]\n",
      " [0.68880805 0.9491471  0.853429   0.89214803]\n",
      " [0.68150246 0.95545521 0.86936132 0.895783  ]\n",
      " [0.72926288 0.95930096 0.8756459  0.89529451]\n",
      " [0.73464785 0.96357295 0.88634457 0.89965432]\n",
      " [0.69353141 0.96643149 0.88771649 0.8996106 ]\n",
      " [0.72760884 0.96878944 0.89316298 0.90015819]]\n",
      "\n",
      "\n",
      "The AUC score matrix of all models for balanced datasets is shown below:\n",
      "\n",
      "[[0.75632494 0.97118978 0.8930501  0.89862011]\n",
      " [0.75861695 0.97152751 0.891235   0.89652483]\n",
      " [0.7593268  0.97146553 0.8908188  0.89631971]\n",
      " [0.68102486 0.97234931 0.89288063 0.89840103]\n",
      " [0.68596378 0.97098602 0.89658144 0.90173901]\n",
      " [0.75913533 0.97118249 0.89641191 0.89970636]\n",
      " [0.7600777  0.97198592 0.89379502 0.90087058]\n",
      " [0.75070462 0.97071539 0.89398639 0.89810796]\n",
      " [0.73025727 0.96949897 0.89164563 0.90151234]\n",
      " [0.62918574 0.9695542  0.89495782 0.90285464]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix for balance of datasets\n",
    "\n",
    "auc_matrix_imbalance = AUC_Score_Matrix(imbalanced_datasets)\n",
    "auc_matrix_balance = AUC_Score_Matrix(balanced_datasets)\n",
    "\n",
    "print(\"The AUC score matrix of all models for imbalanced datasets is shown below:\\n\")\n",
    "print(auc_matrix_imbalance)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The AUC score matrix of all models for balanced datasets is shown below:\\n\")\n",
    "print(auc_matrix_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "23e58656-7498-4518-a82a-b5d0a105c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_imbalance = pd.DataFrame(auc_matrix_imbalance, columns = classifiers)\n",
    "df_auc_balance = pd.DataFrame(auc_matrix_balance, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_imbalance.to_csv('pythonAUC_imbalanced_datasets.csv', index = False)\n",
    "df_auc_balance.to_csv('pythonAUC_balanced_datasets.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19fd4db-3c74-416b-9ce7-52012e632461",
   "metadata": {},
   "source": [
    "### 5.3 AUC score matrix - C. Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bea81794-a785-474b-bf83-80b194f2684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96356265 0.98767048 0.96796982 0.98477041]\n",
      " [0.95865422 0.98858624 0.96180403 0.97719382]\n",
      " [0.95227353 0.9860978  0.96336822 0.97895566]\n",
      " [0.93970242 0.9856204  0.95393315 0.97702892]\n",
      " [0.940801   0.983419   0.94843281 0.96962831]\n",
      " [0.92374383 0.98403034 0.9479038  0.96055243]\n",
      " [0.91923198 0.98162876 0.93917775 0.95622085]\n",
      " [0.89566397 0.97141951 0.92423056 0.93838743]\n",
      " [0.77874233 0.95172647 0.90444976 0.8128372 ]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of number of features - ds75\n",
    "\n",
    "auc_matrix_features_ds75 = AUC_Score_Matrix(features_ds75)\n",
    "print(auc_matrix_features_ds75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "17ab1c1a-ccdd-4c67-87a8-61e8aed02773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_ds75 = pd.DataFrame(auc_matrix_features_ds75, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_ds75.to_csv('pythonAUC_feratures_ds75.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "52a3eb16-cca5-4025-b1fc-4e6c6f80a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62317714 0.58736983 0.52568898 0.60818623]\n",
      " [0.61561493 0.57803666 0.52275834 0.60104791]\n",
      " [0.61383079 0.57356113 0.52095043 0.59726097]\n",
      " [0.60600964 0.56178836 0.51842288 0.59102936]\n",
      " [0.59004378 0.54699183 0.51987069 0.57661412]\n",
      " [0.59097643 0.53297904 0.52044847 0.57798509]\n",
      " [0.58806349 0.53433266 0.52336219 0.57347874]\n",
      " [0.56142889 0.5297608  0.51348229 0.54027196]\n",
      " [0.5071057  0.50349046 0.50262378 0.50089198]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of number of features - ds367\n",
    "\n",
    "auc_matrix_features_ds367 = AUC_Score_Matrix(features_ds367)\n",
    "print(auc_matrix_features_ds367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f8537099-e0e4-49fc-ba97-7d96e72f6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_ds367 = pd.DataFrame(auc_matrix_features_ds367, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_ds367.to_csv('pythonAUC_feratures_ds367.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c94dcce5-c560-4c03-9d36-3bf2c68dee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98862278 0.99251354 0.98260478 0.99051347]\n",
      " [0.98673006 0.99236434 0.98160905 0.9894059 ]\n",
      " [0.9873352  0.9916819  0.9817589  0.98946139]\n",
      " [0.98578217 0.99135431 0.9792632  0.98866355]\n",
      " [0.98219865 0.99003243 0.97939536 0.98695832]\n",
      " [0.98100975 0.98912696 0.97712601 0.98458984]\n",
      " [0.98095494 0.98882522 0.97721374 0.98542686]\n",
      " [0.97470299 0.98467944 0.97419442 0.97514318]\n",
      " [0.96916639 0.9720296  0.95652958 0.93192881]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of number of features - ds722\n",
    "\n",
    "auc_matrix_features_ds722 = AUC_Score_Matrix(features_ds722)\n",
    "print(auc_matrix_features_ds722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "04dce38d-c9b1-4ae2-8c6f-7cb7d7bc647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_ds722 = pd.DataFrame(auc_matrix_features_ds722, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_ds722.to_csv('pythonAUC_feratures_ds722.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baeb9a5-3c78-4a80-b85d-28057f2e4949",
   "metadata": {},
   "source": [
    "### 5.4 AUC score matrix - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "53a23ea1-ae75-418d-8bf8-f0d336ab6ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score matrix of all models for binary datasets is shown below:\n",
      "\n",
      "[[0.61529356 0.82908794 0.73888883 0.78353723]\n",
      " [0.56436366 0.50433269 0.50166074 0.54165069]\n",
      " [0.981404   0.98505123 0.97258917 0.98230585]\n",
      " [0.78737719 0.90775457 0.84128088 0.88208039]\n",
      " [0.84565902 0.93692565 0.85609032 0.8995241 ]\n",
      " [0.78456777 0.79648749 0.72053529 0.7891202 ]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of binary datasets\n",
    "\n",
    "auc_matrix_binary = AUC_Score_Matrix(binary_datasets)\n",
    "print(\"The AUC score matrix of all models for binary datasets is shown below:\\n\")\n",
    "print(auc_matrix_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8480e106-6be9-4b9f-a9fa-f80cf60e90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_binary = pd.DataFrame(auc_matrix_binary, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_binary.to_csv('pythonAUC_binary_datasets.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1b3b9994-cb99-4df9-ba43-fca67ac0beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score matrix of all models for ordinal datasets is shown below:\n",
      "\n",
      "[[0.94926494 0.9584784  0.88448015 0.95944052]\n",
      " [0.94297964 0.98511828 0.96863441 0.98028775]\n",
      " [0.96852317 0.9644391  0.94627901 0.96782058]\n",
      " [0.89691896 0.99813767 0.98862382 0.96060396]\n",
      " [0.97728336 0.99842006 0.98092447 0.97900958]\n",
      " [0.8355242  0.95993619 0.89806101 0.92693791]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of ordinal datasets\n",
    "\n",
    "auc_matrix_ordinal = AUC_Score_Matrix(ordinal_datasets)\n",
    "print(\"The AUC score matrix of all models for ordinal datasets is shown below:\\n\")\n",
    "print(auc_matrix_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b6b078c5-2a2f-4837-8104-786c1ef70267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_ordinal = pd.DataFrame(auc_matrix_ordinal, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_ordinal.to_csv('pythonAUC_ordinal_datasets.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ca0f029f-6037-4dcd-ab2c-6435775417ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score matrix of all models for categorical datasets is shown below:\n",
      "\n",
      "[[0.89067837 0.97927366 0.95378335 0.97201097]\n",
      " [0.85535156 0.89586345 0.84213093 0.88196876]\n",
      " [0.72292079 0.99845492 0.99643296 0.99770076]\n",
      " [0.69297817 0.99987781 0.99880254 0.99848485]\n",
      " [0.99467637 0.99949505 0.98556658 1.        ]\n",
      " [0.99457239 0.99797856 0.9998644  0.99990138]]\n"
     ]
    }
   ],
   "source": [
    "# AUC score matrix of categorical datasets\n",
    "\n",
    "auc_matrix_categorical = AUC_Score_Matrix(categorical_datasets)\n",
    "print(\"The AUC score matrix of all models for categorical datasets is shown below:\\n\")\n",
    "print(auc_matrix_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8e123284-040e-4d64-a15a-23b4c830043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output matrix to csv file\n",
    "\n",
    "# classifier name\n",
    "classifiers = ['Logistic Regression', 'Random Forest', 'K-Nearest Neighbors', 'Support Vector Machine']\n",
    "\n",
    "# convert matrix to pandas DataFrame\n",
    "df_auc_categorical = pd.DataFrame(auc_matrix_categorical, columns = classifiers)\n",
    "\n",
    "# output dataframe to excel\n",
    "df_auc_categorical.to_csv('pythonAUC_categorical_datasets.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcb8f3",
   "metadata": {},
   "source": [
    "# 6 Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6cc91-8463-46ab-84e8-c1d05b415087",
   "metadata": {},
   "source": [
    "### 6.0 Define model names and comparison function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2a81ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Logistic Regression','Random Forests','K-Nearest Neighbors','Support Vector Machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e9e62676-9039-42dd-a4fd-3b00e28771d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sub_AUC_Vector(auc1, auc2):\n",
    "    auc_diff = auc1 - auc2\n",
    "    auc_diff_dict = {}\n",
    "\n",
    "    # create sub vector from the difference matrix\n",
    "    for i in range(auc_diff.shape[1]): # take every column as datasets of each model\n",
    "        col = auc_diff[:, i]\n",
    "        auc_diff_dict[f\"{model_names[i]}\"] = col\n",
    "    \n",
    "    return auc_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bae98",
   "metadata": {},
   "source": [
    "### 6.1 Comparison - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7653810f-9cd0-4c3c-9d5c-cda17e6c27de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': array([ 0.22205892,  0.07388724,  0.10325924,  0.09139788,  0.08323899,\n",
       "         0.01788327,  0.17028367,  0.09099092,  0.04217973, -0.02216264]),\n",
       " 'Random Forests': array([0.1339418 , 0.05812887, 0.08682511, 0.0975865 , 0.09570233,\n",
       "        0.06599511, 0.05285409, 0.05410002, 0.03855669, 0.0374456 ]),\n",
       " 'K-Nearest Neighbors': array([-0.01239979,  0.02654894,  0.11454833,  0.11810617,  0.12364377,\n",
       "         0.09818674,  0.03326251,  0.05722068,  0.07348575,  0.09254304]),\n",
       " 'Support Vector Machine': array([0.07923351, 0.01057378, 0.08678621, 0.10318263, 0.13021541,\n",
       "        0.07214157, 0.05598773, 0.06532034, 0.06637794, 0.05488215])}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create difference vector based on models\n",
    "\n",
    "difference_large_small = Sub_AUC_Vector(auc_matrix_large, auc_matrix_small)\n",
    "difference_large_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a4e1a-0666-40f5-a54f-231a01a05d95",
   "metadata": {},
   "source": [
    "### 6.2 Comparison - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "786e1631-8755-4c45-8f70-21aa7c427540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': array([ 0.13515674,  0.20445249,  0.17533286,  0.05471307, -0.00284428,\n",
       "         0.07763287,  0.03081482,  0.01605677,  0.03672587, -0.09842309]),\n",
       " 'Random Forests': array([0.06548477, 0.08235964, 0.04566198, 0.03019524, 0.02183893,\n",
       "        0.01572728, 0.01268497, 0.00714244, 0.00306748, 0.00076476]),\n",
       " 'K-Nearest Neighbors': array([0.04941083, 0.20343998, 0.12216954, 0.06733175, 0.04315244,\n",
       "        0.0270506 , 0.01814911, 0.00764183, 0.00392914, 0.00179484]),\n",
       " 'Support Vector Machine': array([ 0.00371109,  0.04788447,  0.0214363 ,  0.01054056,  0.00959098,\n",
       "         0.00392336,  0.00557607, -0.00154636,  0.00190175,  0.00269645])}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualte the difference score between balanced and imbalanced datasets\n",
    "\n",
    "difference_balance_imbalance = Sub_AUC_Vector(auc_matrix_balance, auc_matrix_imbalance)\n",
    "difference_balance_imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a66b09-89c1-4bea-8116-3615d89d9810",
   "metadata": {},
   "source": [
    "### 6.3 Comparison - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b301a-176f-4e2b-8d0a-fe8f7d107d9c",
   "metadata": {},
   "source": [
    "#### 6.3.1 binary vs. ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3114dd2d-a70f-464a-b742-4d19e31f86f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': array([ 0.33397138,  0.37861598, -0.01288083,  0.10954177,  0.13162434,\n",
       "         0.05095643]),\n",
       " 'Random Forests': array([ 0.12939046,  0.48078558, -0.02061213,  0.0903831 ,  0.06149441,\n",
       "         0.1634487 ]),\n",
       " 'K-Nearest Neighbors': array([ 0.14559132,  0.46697367, -0.02631016,  0.14734294,  0.12483414,\n",
       "         0.17752572]),\n",
       " 'Support Vector Machine': array([ 0.17590329,  0.43863705, -0.01448527,  0.07852357,  0.07948548,\n",
       "         0.1378177 ])}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the difference between ordinal and binay datatsets\n",
    "\n",
    "difference_ordinal_binary = Sub_AUC_Vector(auc_matrix_ordinal, auc_matrix_binary)\n",
    "difference_ordinal_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a08d0-c2d6-4525-aaf0-e5e9e3300541",
   "metadata": {},
   "source": [
    "#### 6.3.2 binary vs. categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "c9a489f8-923f-4f15-bd99-de26c949be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': array([ 0.27538481,  0.29098791, -0.25848321, -0.09439902,  0.14901735,\n",
       "         0.21000462]),\n",
       " 'Random Forests': array([0.15018572, 0.39153076, 0.0134037 , 0.09212324, 0.06256941,\n",
       "        0.20149107]),\n",
       " 'K-Nearest Neighbors': array([0.21489453, 0.34047019, 0.02384379, 0.15752166, 0.12947626,\n",
       "        0.2793291 ]),\n",
       " 'Support Vector Machine': array([0.18847374, 0.34031807, 0.01539492, 0.11640446, 0.1004759 ,\n",
       "        0.21078118])}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the difference between categorical and binary datasets\n",
    "\n",
    "difference_categorical_binary = Sub_AUC_Vector(auc_matrix_categorical, auc_matrix_binary)\n",
    "difference_categorical_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c5423-227c-4100-b4ea-e1889c6a9f5a",
   "metadata": {},
   "source": [
    "# 7 Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5f0d5-b0ad-4dc3-9339-4cb2ff2098a5",
   "metadata": {},
   "source": [
    "### 7.0 Define functions for hypothesis tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1aa33e32-38c3-4a02-a6b0-e83fc27373ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of wilcoxon signed rank test for every classifier\n",
    "\n",
    "def Wilcoxon_single_model(difference_dict):\n",
    "    for name, vector in difference_dict.items():\n",
    "        stat, p_value = wilcoxon(vector)\n",
    "        print(f\"Hypothesis test for {name} model:\\n U Statistic: {stat}, p-Value: {p_value}\")\n",
    "        if p_value < 0.05:\n",
    "            print(f\"{name} performs significantly different on above two kinds of datasets!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "842093ab-3dc7-4f07-9b31-3e55a4ba1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of Mann-Kendall trend test for every classifier\n",
    "\n",
    "def MannKendall_trend_test(auc_matrix):\n",
    "    n_column = matrix.shape[1]\n",
    "    trend_result = []\n",
    "    \n",
    "    for i in range(n_column):\n",
    "        column = auc_matrix[:, i]\n",
    "        result = mk.original_test(column)\n",
    "        trend_result.append(result)\n",
    "        \n",
    "    for index, res in enumerate(trend_result):\n",
    "        if index == 0:\n",
    "            print(f\"Logistic Regression: Trend = {res.trend}, S statistic: {res.s}, P-value = {res.p}\")\n",
    "        elif index == 1:\n",
    "            print(f\"Random Forest: Trend = {res.trend}, S statistic: {res.s}, P-value = {res.p}\")\n",
    "        elif index == 2:\n",
    "            print(f\"K-Nearest Neighbors: Trend = {res.trend}, S statistic: {res.s}, P-value = {res.p}\")\n",
    "        elif index == 3:\n",
    "            print(f\"Support Vector Machine: Trend = {res.trend}, S statistic: {res.s}, P-value = {res.p}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b88af363-90fe-4a2a-a226-1835dfab8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of wilcoxon signed rank test for pariwise classifiers\n",
    "\n",
    "def Wilcoxon_pairwise_model(difference_dict):\n",
    "    for i in range(len(model_names)):\n",
    "        for j in range(i+1, len(model_names)):\n",
    "            name1 = model_names[i]\n",
    "            name2 = model_names[j]\n",
    "            vector1 = difference_dict[name1]\n",
    "            vector2 = difference_dict[name2]\n",
    "\n",
    "            # check whether they are significantly different\n",
    "            stat_1, p_value_1 = wilcoxon(vector1, vector2)\n",
    "            print(f\"{name1} vs. {name2}\\n U Statistic: {stat_1}, p-Value: {p_value_1}\")\n",
    "\n",
    "            # further check which one is better\n",
    "            if p_value_1 < 0.05:\n",
    "                print(f\"The degree of differences between {name1} and {name2} is statistically significant!\")\n",
    "\n",
    "            # compare signed rank\n",
    "                more = 0\n",
    "                less = 0\n",
    "                for p in vector1:\n",
    "                    for q in vector2:\n",
    "                        if p - q > 0:\n",
    "                            more += 1\n",
    "                        elif p - q <0:\n",
    "                            less += 1\n",
    "\n",
    "                if more > less:\n",
    "                    print(f\"The degree of differences of {name1} in size of datasets is significantly larger than {name2}!\")\n",
    "                elif more < less:\n",
    "                    print(f\"The degree of differences of {name2} in size of datasets is significantly larger than {name1}!\")\n",
    "                print(\"\\n\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"The degree of differences between {name1} and {name2} is not statistically significant!\")\n",
    "                print(\"\\n\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce6ff1-02fd-40b4-ba35-755d286c01de",
   "metadata": {},
   "source": [
    "### 7.1 Single Classifier Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393aeae",
   "metadata": {},
   "source": [
    "#### 7.1.1 Wilcoxon-Signed Rank Test - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b2a8ca06-4569-4388-b15f-5c34cb36fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis test for Logistic Regression model:\n",
      " U Statistic: 2.0, p-Value: 0.005859375\n",
      "Logistic Regression performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for Random Forests model:\n",
      " U Statistic: 0.0, p-Value: 0.001953125\n",
      "Random Forests performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for K-Nearest Neighbors model:\n",
      " U Statistic: 1.0, p-Value: 0.00390625\n",
      "K-Nearest Neighbors performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for Support Vector Machine model:\n",
      " U Statistic: 0.0, p-Value: 0.001953125\n",
      "Support Vector Machine performs significantly different on above two kinds of datasets!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon signed rank test for every classifier between large and small datasets\n",
    "\n",
    "Wilcoxon_single_model(difference_large_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff173a-0156-4789-a0c8-13d345b41319",
   "metadata": {},
   "source": [
    "#### 7.1.2 Wilcoxon-Signed Rank Test - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e5b261e7-668d-47e8-88bd-cc3fdbde47b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis test for Logistic Regression model:\n",
      " U Statistic: 8.0, p-Value: 0.048828125\n",
      "Logistic Regression performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for Random Forests model:\n",
      " U Statistic: 0.0, p-Value: 0.001953125\n",
      "Random Forests performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for K-Nearest Neighbors model:\n",
      " U Statistic: 0.0, p-Value: 0.001953125\n",
      "K-Nearest Neighbors performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for Support Vector Machine model:\n",
      " U Statistic: 1.0, p-Value: 0.00390625\n",
      "Support Vector Machine performs significantly different on above two kinds of datasets!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon signed rank test for every classifier between balanced and imbalanced datasets\n",
    "\n",
    "Wilcoxon_single_model(difference_balance_imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae8e9b-826a-44be-957e-85623474cae2",
   "metadata": {},
   "source": [
    "#### 7.1.3 Mann-Kendall Trend test - C. Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cfff6963-2fad-4b19-9755-22f6de0c0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n",
      "Random Forest: Trend = decreasing, S statistic: -32.0, P-value = 0.0012293849189448647\n",
      "K-Nearest Neighbors: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n",
      "Support Vector Machine: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n"
     ]
    }
   ],
   "source": [
    "# Mann-Kendall trend test in feature dimensionality for ds75\n",
    "\n",
    "MannKendall_trend_test(auc_matrix_features_ds75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a2188bf5-6c6e-4a89-a1aa-729c1e2289c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n",
      "Random Forest: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n",
      "K-Nearest Neighbors: Trend = decreasing, S statistic: -20.0, P-value = 0.04760395472787149\n",
      "Support Vector Machine: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n"
     ]
    }
   ],
   "source": [
    "# Mann-Kendall trend test in feature dimensionality for ds367\n",
    "\n",
    "MannKendall_trend_test(auc_matrix_features_ds367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7c984326-8a4d-4ae1-a898-2703cfc4037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Trend = decreasing, S statistic: -34.0, P-value = 0.0005806665459491267\n",
      "Random Forest: Trend = decreasing, S statistic: -36.0, P-value = 0.00026326080270355767\n",
      "K-Nearest Neighbors: Trend = decreasing, S statistic: -30.0, P-value = 0.0024990288576112185\n",
      "Support Vector Machine: Trend = decreasing, S statistic: -32.0, P-value = 0.0012293849189448647\n"
     ]
    }
   ],
   "source": [
    "# Mann-Kendall trend test in feature dimensionality for ds722\n",
    "\n",
    "MannKendall_trend_test(auc_matrix_features_ds722)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732e7b7-5d5e-468f-81c9-64b82b325212",
   "metadata": {},
   "source": [
    "#### 7.1.4 Wilcoxon-Signed Rank Test - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "39273597-e546-47c4-b156-59f9d9b260b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis test for Logistic Regression model:\n",
      " U Statistic: 1.0, p-Value: 0.0625\n",
      "Hypothesis test for Random Forests model:\n",
      " U Statistic: 1.0, p-Value: 0.0625\n",
      "Hypothesis test for K-Nearest Neighbors model:\n",
      " U Statistic: 1.0, p-Value: 0.0625\n",
      "Hypothesis test for Support Vector Machine model:\n",
      " U Statistic: 1.0, p-Value: 0.0625\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon signed rank test: between binary and ordinal datasets\n",
    "\n",
    "Wilcoxon_single_model(difference_ordinal_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "42052e46-7e9a-47b5-8119-6b5512e2b91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis test for Logistic Regression model:\n",
      " U Statistic: 5.0, p-Value: 0.3125\n",
      "Hypothesis test for Random Forests model:\n",
      " U Statistic: 0.0, p-Value: 0.03125\n",
      "Random Forests performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for K-Nearest Neighbors model:\n",
      " U Statistic: 0.0, p-Value: 0.03125\n",
      "K-Nearest Neighbors performs significantly different on above two kinds of datasets!\n",
      "\n",
      "Hypothesis test for Support Vector Machine model:\n",
      " U Statistic: 0.0, p-Value: 0.03125\n",
      "Support Vector Machine performs significantly different on above two kinds of datasets!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon signed rank test: between binary and categorical datasets\n",
    "\n",
    "Wilcoxon_single_model(difference_categorical_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19abbed",
   "metadata": {},
   "source": [
    "### 7.2 Pairwise Classifiers Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d300ea",
   "metadata": {},
   "source": [
    "#### 7.2.1 Wilcoxon-Signed Rank Test - A. Size of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9a5ad47e-076e-4e48-8770-eb1ad9704dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression vs. Random Forests\n",
      " U Statistic: 20.0, p-Value: 0.4921875\n",
      "The degree of differences between Logistic Regression and Random Forests is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. K-Nearest Neighbors\n",
      " U Statistic: 26.0, p-Value: 0.921875\n",
      "The degree of differences between Logistic Regression and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. Support Vector Machine\n",
      " U Statistic: 23.0, p-Value: 0.6953125\n",
      "The degree of differences between Logistic Regression and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. K-Nearest Neighbors\n",
      " U Statistic: 18.0, p-Value: 0.375\n",
      "The degree of differences between Random Forests and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. Support Vector Machine\n",
      " U Statistic: 20.0, p-Value: 0.4921875\n",
      "The degree of differences between Random Forests and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "K-Nearest Neighbors vs. Support Vector Machine\n",
      " U Statistic: 20.0, p-Value: 0.4921875\n",
      "The degree of differences between K-Nearest Neighbors and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon pairwise test: large vs. small\n",
    "\n",
    "Wilcoxon_pairwise_model(difference_large_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523449eb-eb74-47b3-8fa1-741574640ec1",
   "metadata": {},
   "source": [
    "#### 7.2.2 Wilcoxon-Signed Rank Test - B. Balance of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3a0c1994-c968-481f-b732-be20910bb14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression vs. Random Forests\n",
      " U Statistic: 12.0, p-Value: 0.130859375\n",
      "The degree of differences between Logistic Regression and Random Forests is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. K-Nearest Neighbors\n",
      " U Statistic: 19.0, p-Value: 0.431640625\n",
      "The degree of differences between Logistic Regression and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. Support Vector Machine\n",
      " U Statistic: 8.0, p-Value: 0.048828125\n",
      "The degree of differences between Logistic Regression and Support Vector Machine is statistically significant!\n",
      "The degree of differences of Logistic Regression in size of datasets is significantly larger than Support Vector Machine!\n",
      "\n",
      "\n",
      "Random Forests vs. K-Nearest Neighbors\n",
      " U Statistic: 6.0, p-Value: 0.02734375\n",
      "The degree of differences between Random Forests and K-Nearest Neighbors is statistically significant!\n",
      "The degree of differences of K-Nearest Neighbors in size of datasets is significantly larger than Random Forests!\n",
      "\n",
      "\n",
      "Random Forests vs. Support Vector Machine\n",
      " U Statistic: 2.0, p-Value: 0.005859375\n",
      "The degree of differences between Random Forests and Support Vector Machine is statistically significant!\n",
      "The degree of differences of Random Forests in size of datasets is significantly larger than Support Vector Machine!\n",
      "\n",
      "\n",
      "K-Nearest Neighbors vs. Support Vector Machine\n",
      " U Statistic: 1.0, p-Value: 0.00390625\n",
      "The degree of differences between K-Nearest Neighbors and Support Vector Machine is statistically significant!\n",
      "The degree of differences of K-Nearest Neighbors in size of datasets is significantly larger than Support Vector Machine!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon pairwise test: balance vs. imbalance\n",
    "\n",
    "Wilcoxon_pairwise_model(difference_balance_imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d6d18-a55c-43bf-a0ee-1e1cd6907fec",
   "metadata": {},
   "source": [
    "#### 7.2.3 Wilcoxon-Signed Rank Test - D. Binary or non-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ba2e27a5-664c-4e3f-9421-94ccaf04f453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression vs. Random Forests\n",
      " U Statistic: 9.0, p-Value: 0.84375\n",
      "The degree of differences between Logistic Regression and Random Forests is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. K-Nearest Neighbors\n",
      " U Statistic: 9.0, p-Value: 0.84375\n",
      "The degree of differences between Logistic Regression and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. Support Vector Machine\n",
      " U Statistic: 9.0, p-Value: 0.84375\n",
      "The degree of differences between Logistic Regression and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. K-Nearest Neighbors\n",
      " U Statistic: 3.0, p-Value: 0.15625\n",
      "The degree of differences between Random Forests and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. Support Vector Machine\n",
      " U Statistic: 10.0, p-Value: 1.0\n",
      "The degree of differences between Random Forests and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "K-Nearest Neighbors vs. Support Vector Machine\n",
      " U Statistic: 4.0, p-Value: 0.21875\n",
      "The degree of differences between K-Nearest Neighbors and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon pairwise test: ordinal vs. binary\n",
    "\n",
    "Wilcoxon_pairwise_model(difference_ordinal_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "016245a2-a45e-4018-a3c4-8f0cec7f7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression vs. Random Forests\n",
      " U Statistic: 7.0, p-Value: 0.5625\n",
      "The degree of differences between Logistic Regression and Random Forests is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. K-Nearest Neighbors\n",
      " U Statistic: 4.0, p-Value: 0.21875\n",
      "The degree of differences between Logistic Regression and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Logistic Regression vs. Support Vector Machine\n",
      " U Statistic: 6.0, p-Value: 0.4375\n",
      "The degree of differences between Logistic Regression and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. K-Nearest Neighbors\n",
      " U Statistic: 2.0, p-Value: 0.09375\n",
      "The degree of differences between Random Forests and K-Nearest Neighbors is not statistically significant!\n",
      "\n",
      "\n",
      "Random Forests vs. Support Vector Machine\n",
      " U Statistic: 6.0, p-Value: 0.4375\n",
      "The degree of differences between Random Forests and Support Vector Machine is not statistically significant!\n",
      "\n",
      "\n",
      "K-Nearest Neighbors vs. Support Vector Machine\n",
      " U Statistic: 0.0, p-Value: 0.03125\n",
      "The degree of differences between K-Nearest Neighbors and Support Vector Machine is statistically significant!\n",
      "The degree of differences of K-Nearest Neighbors in size of datasets is significantly larger than Support Vector Machine!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wilcoxon pairwise test: categorical vs. binary\n",
    "\n",
    "Wilcoxon_pairwise_model(difference_categorical_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c50d0-b6df-4dc5-a995-11d897df9c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
